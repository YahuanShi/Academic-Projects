# Deep Learning

## 🎯 Course Description

This course covers both foundational and advanced deep learning concepts. It includes mathematical formulations, optimization, regularization, and state-of-the-art neural architectures. Students gain practical skills using modern deep learning frameworks (e.g. PyTorch), and explore applications such as generative modeling, graph learning, and reinforcement learning.

---

## 📘 Learning Outcomes

Upon completing this course, I was able to:

- Understand and implement neural networks using PyTorch
- Apply techniques such as SGD, momentum, dropout, weight decay, and Lipschitz regularization
- Analyze architectures including CNNs, RNNs, autoencoders, Transformers, and Graph Neural Networks
- Understand and apply deep learning techniques in anomaly detection, explainability, generative modeling, and reinforcement learning

---

## 🧠 Lecture Topics

| Lecture | Topic |
|---------|--------------------------------------------------------------|
| 01 | [Backpropagation](./01-backpropagation) |
| 02 | [Optimization A](./02-optimization-a) |
| 03 | [Optimization B](./03-optimization-b) |
| 04 | [Regularization A](./04-regularization-a) |
| 05 | [Regularization B](./05-regularization-b) |
| 06 | [Loss Functions](./06-loss-functions) |
| 07 | [Convolutional Networks](./07-convolutional-networks) |
| 08 | [Recurrent Neural Networks](./08-recurrent-neural-networks) |
| 09 | [Autoencoders](./09-autoencoders) |
| 10 | [Structured Output](./10-structured-output) |
| 11 | [Explainable AI](./11-explainable-ai) |
| 12 | [Representation Learning](./12-representation-learning) |
| 13 | [Attention & Transformers](./13-attention-transformers) |
| 14 | [Graph Neural Networks](./14-graph-neural-networks) |
| 15 | [Equivariant NNs](./15-equivariant-nns) |
| 16 | [Advanced XAI](./16-advanced-xai) |
| 17 | [Neural ODEs](./17-neural-odes) |
| 18 | [Density Estimation](./18-density-estimation) |
| 19 | [Generative Models](./19-generative-models) |
| 20 | [Reinforcement Learning](./20-reinforcement-learning) |

---

## 🛠️ Tools & Libraries

- PyTorch
- Matplotlib
- NumPy
- TensorBoard (optional)
- scikit-learn (for comparison)

---

## 📁 Assignments

Each lecture includes code exercises and theoretical questions.  
Relevant `.ipynb` notebooks and written reports are placed inside the lecture folders.

---

> 📂 Browse each topic to find detailed implementations and explanations.
